{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Exceptions\n",
    "\n",
    "In this notebook, we'll explore how to handle exceptions effectively. Exception handling is crucial for building robust and maintainable code, especially in complex workflows. We'll cover best practices, demonstrate how to implement them in a data science context, and illustrate advanced techniques such as using custom exceptions and ensuring clean error handling across nested functions.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Basic Exception Handling](#1)\n",
    "2. [Custom Exceptions](#2)\n",
    "3. [Nested Functions and Exception Propagation](#3)\n",
    "4. [Logging Exceptions](#4)\n",
    "5. [Step-by-Step Example](#5)\n",
    "6. [Exercise](#6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Basic Exception Handling <a name=\"1\"></a>\n",
    "\n",
    "Exception handling allows your code to deal with errors gracefully. Here's a simple example of handling an exception in a data loading step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_data(filepath):\n",
    "    try:\n",
    "        data = pd.read_csv(filepath)\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file at {filepath} was not found.\")\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(\"Error: No data in file.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "# Usage\n",
    "data = load_data('data/raw/non_existent_file.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "2. Custom Exceptions <a name=\"2\"></a>\n",
    "\n",
    "Creating custom exceptions allows you to handle specific error conditions more gracefully.\n",
    "\n",
    "python\n",
    "\n",
    "class DataValidationError(Exception):\n",
    "    pass\n",
    "\n",
    "def validate_data(data):\n",
    "    if data.isnull().sum().sum() > 0:\n",
    "        raise DataValidationError(\"Data contains missing values.\")\n",
    "\n",
    "# Usage\n",
    "try:\n",
    "    data = load_data('data/raw/example.csv')\n",
    "    validate_data(data)\n",
    "except DataValidationError as e:\n",
    "    print(f\"Validation Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "3. Nested Functions and Exception Propagation <a name=\"3\"></a>\n",
    "\n",
    "Handling exceptions in nested functions ensures that errors are caught and managed properly, preventing unexpected crashes.\n",
    "\n",
    "python\n",
    "\n",
    "def preprocess_data(data):\n",
    "    try:\n",
    "        # Example preprocessing step\n",
    "        data['new_column'] = data['existing_column'] * 2\n",
    "        return data\n",
    "    except KeyError as e:\n",
    "        raise DataValidationError(f\"Missing column during preprocessing: {e}\")\n",
    "\n",
    "def run_pipeline(filepath):\n",
    "    try:\n",
    "        data = load_data(filepath)\n",
    "        validate_data(data)\n",
    "        data = preprocess_data(data)\n",
    "        return data\n",
    "    except DataValidationError as e:\n",
    "        print(f\"Data validation failed: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred in the pipeline: {e}\")\n",
    "\n",
    "# Usage\n",
    "processed_data = run_pipeline('data/raw/example.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "4. Logging Exceptions <a name=\"4\"></a>\n",
    "\n",
    "Using logging for exception handling provides a more flexible and powerful way to manage errors, especially in production environments.\n",
    "\n",
    "python\n",
    "\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def load_data(filepath):\n",
    "    try:\n",
    "        data = pd.read_csv(filepath)\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        logger.error(f\"File not found: {filepath}\")\n",
    "        raise\n",
    "    except pd.errors.EmptyDataError:\n",
    "        logger.error(\"No data in file.\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An unexpected error occurred: {e}\")\n",
    "        raise\n",
    "\n",
    "# Usage\n",
    "try:\n",
    "    data = load_data('data/raw/non_existent_file.csv')\n",
    "except Exception as e:\n",
    "    logger.critical(f\"Critical error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "5. Step-by-Step Example <a name=\"5\"></a>\n",
    "\n",
    "We'll now build a complete data science pipeline with exception handling at each step.\n",
    "Step 1: Data Loading\n",
    "\n",
    "python\n",
    "\n",
    "def load_data(filepath):\n",
    "    try:\n",
    "        data = pd.read_csv(filepath)\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        logger.error(f\"File not found: {filepath}\")\n",
    "        raise\n",
    "    except pd.errors.EmptyDataError:\n",
    "        logger.error(\"No data in file.\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An unexpected error occurred: {e}\")\n",
    "        raise\n",
    "\n",
    "Step 2: Data Validation\n",
    "\n",
    "python\n",
    "\n",
    "class DataValidationError(Exception):\n",
    "    pass\n",
    "\n",
    "def validate_data(data):\n",
    "    try:\n",
    "        if data.isnull().sum().sum() > 0:\n",
    "            raise DataValidationError(\"Data contains missing values.\")\n",
    "    except DataValidationError as e:\n",
    "        logger.warning(f\"Validation error: {e}\")\n",
    "        raise\n",
    "\n",
    "Step 3: Data Preprocessing\n",
    "\n",
    "python\n",
    "\n",
    "def preprocess_data(data):\n",
    "    try:\n",
    "        data['new_column'] = data['existing_column'] * 2\n",
    "        return data\n",
    "    except KeyError as e:\n",
    "        logger.error(f\"Missing column during preprocessing: {e}\")\n",
    "        raise DataValidationError(f\"Preprocessing error: {e}\")\n",
    "\n",
    "Step 4: Running the Pipeline\n",
    "\n",
    "python\n",
    "\n",
    "def run_pipeline(filepath):\n",
    "    try:\n",
    "        data = load_data(filepath)\n",
    "        validate_data(data)\n",
    "        data = preprocess_data(data)\n",
    "        return data\n",
    "    except DataValidationError as e:\n",
    "        logger.error(f\"Pipeline failed: {e}\")\n",
    "    except Exception as e:\n",
    "        logger.critical(f\"Critical error in pipeline: {e}\")\n",
    "\n",
    "# Usage\n",
    "processed_data = run_pipeline('data/raw/example.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "6. Exercise <a name=\"6\"></a>\n",
    "Task\n",
    "\n",
    "You are provided with a simple data science pipeline that loads data, validates it, preprocesses it, and trains a model. The pipeline currently does not have any exception handling. Your task is to:\n",
    "\n",
    "    Add exception handling to each step of the pipeline.\n",
    "    Use custom exceptions where appropriate.\n",
    "    Implement logging for all exceptions.\n",
    "\n",
    "Initial Code\n",
    "\n",
    "python\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_data(filepath):\n",
    "    data = pd.read_csv(filepath)\n",
    "    return data\n",
    "\n",
    "def validate_data(data):\n",
    "    if data.isnull().sum().sum() > 0:\n",
    "        print(\"Data contains missing values.\")\n",
    "\n",
    "def preprocess_data(data):\n",
    "    data['new_column'] = data['existing_column'] * 2\n",
    "    return data\n",
    "\n",
    "def train_model(data):\n",
    "    X = data[['new_column']]\n",
    "    y = data['target']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "def run_pipeline(filepath):\n",
    "    data = load_data(filepath)\n",
    "    validate_data(data)\n",
    "    data = preprocess_data(data)\n",
    "    model = train_model(data)\n",
    "    return model\n",
    "\n",
    "# Usage\n",
    "model = run_pipeline('data/raw/example.csv')\n",
    "print(model)\n",
    "\n",
    "Requirements\n",
    "\n",
    "    Handle file not found errors in load_data.\n",
    "    Raise a custom exception for validation errors in validate_data.\n",
    "    Handle missing column errors in preprocess_data.\n",
    "    Handle any errors during model training in train_model.\n",
    "    Log all exceptions with appropriate severity levels.\n",
    "\n",
    "Solution\n",
    "\n",
    "python\n",
    "\n",
    "import pandas as pd\n",
    "import logging\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class DataValidationError(Exception):\n",
    "    pass\n",
    "\n",
    "def load_data(filepath):\n",
    "    try:\n",
    "        data = pd.read_csv(filepath)\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        logger.error(f\"File not found: {filepath}\")\n",
    "        raise\n",
    "    except pd.errors.EmptyDataError:\n",
    "        logger.error(\"No data in file.\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An unexpected error occurred: {e}\")\n",
    "        raise\n",
    "\n",
    "def validate_data(data):\n",
    "    try:\n",
    "        if data.isnull().sum().sum() > 0:\n",
    "            raise DataValidationError(\"Data contains missing values.\")\n",
    "    except DataValidationError as e:\n",
    "        logger.warning(f\"Validation error: {e}\")\n",
    "        raise\n",
    "\n",
    "def preprocess_data(data):\n",
    "    try:\n",
    "        data['new_column'] = data['existing_column'] * 2\n",
    "        return data\n",
    "    except KeyError as e:\n",
    "        logger.error(f\"Missing column during preprocessing: {e}\")\n",
    "        raise DataValidationError(f\"Preprocessing error: {e}\")\n",
    "\n",
    "def train_model(data):\n",
    "    try:\n",
    "        X = data[['new_column']]\n",
    "        y = data['target']\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "        return model\n",
    "    except KeyError as e:\n",
    "        logger.error(f\"Missing target column: {e}\")\n",
    "        raise DataValidationError(f\"Training error: {e}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred during model training: {e}\")\n",
    "        raise\n",
    "\n",
    "def run_pipeline(filepath):\n",
    "    try:\n",
    "        data = load_data(filepath)\n",
    "        validate_data(data)\n",
    "        data = preprocess_data(data)\n",
    "        model = train_model(data)\n",
    "        return model\n",
    "    except DataValidationError as e:\n",
    "        logger.error(f\"Pipeline failed: {e}\")\n",
    "    except Exception as e:\n",
    "        logger.critical(f\"Critical error in pipeline: {e}\")\n",
    "\n",
    "# Usage\n",
    "try:\n",
    "    model = run_pipeline('data/raw/example.csv')\n",
    "    print(model)\n",
    "except Exception as e:\n",
    "    logger.critical(f\"Pipeline execution failed: {e}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
